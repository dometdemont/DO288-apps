{
  "types": {
    "NetworkFunctions": [
    ],
    "IndirectServices": [
      "jenkins",
      "elasticsearch",
      "telegraf",
      "prometheus-alertmanager",
      "prometheus",
      "kube-state-metrics",
      "pushgateway",
      "grafana"
    ],
    "DirectServices": [
      "ignite",
      "redis",
      "redis-nopwd",
      "influxdb",
      "fluentd"
    ],
    "Operators": [
      "jaeger-product",
      "cert-manager",
      "servicemeshoperator",
      "amq-streams",
      "elasticsearch-operator",
      "kiali-ossm",
      "grafana-operator",
      "prometheus-operator"
    ],
    "HelmCharts": [
    ]
  },
  "dependencies": {
    
  },
  "values": {
    "jenkins": {
      "URL": "quay.io/openshift",
      "image": "origin-jenkins",
      "tag": "latest",
      "template": "\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source\n- kind: Route\n  apiVersion: v1\n  metadata:\n    annotations:\n      haproxy.router.openshift.io/timeout: 4m\n      template.openshift.io/expose-uri: http://{.spec.host}{.spec.path}\n    name: ~NAME~\n  spec:\n    tls:\n      insecureEdgeTerminationPolicy: Redirect\n      termination: edge\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    annotations:\n      template.alpha.openshift.io/wait-for-ready: \"true\"\n    name: ~NAME~\n  spec:\n    replicas: 1\n    selector:\n      name: ~NAME~\n    strategy:\n      type: Recreate\n    template:\n      metadata:\n        labels:\n          name: ~NAME~\n      spec:\n        containers:\n        - capabilities: {}\n          env:\n          - name: OPENSHIFT_ENABLE_OAUTH\n            value: \"true\"\n          - name: OPENSHIFT_ENABLE_REDIRECT_PROMPT\n            value: \"true\"\n          - name: KUBERNETES_MASTER\n            value: https://kubernetes.default:443\n          - name: KUBERNETES_TRUST_CERTIFICATES\n            value: \"true\"\n          - name: JENKINS_SERVICE_NAME\n            value: ~NAME~\n          - name: JNLP_SERVICE_NAME\n            value: ~NAME~-jnlp\n          image: ~IMAGE_STREAM~\n          imagePullPolicy: IfNotPresent\n          livenessProbe:\n            failureThreshold: 2\n            httpGet:\n              path: /login\n              port: 8080\n            initialDelaySeconds: 420\n            periodSeconds: 360\n            timeoutSeconds: 240\n          name: jenkins\n          readinessProbe:\n            httpGet:\n              path: /login\n              port: 8080\n            initialDelaySeconds: 3\n            timeoutSeconds: 240\n          resources:\n            limits:\n              memory: 2048Mi\n          securityContext:\n            capabilities: {}\n            privileged: false\n          terminationMessagePath: /dev/termination-log\n          volumeMounts:\n          - mountPath: /var/lib/jenkins\n            name: ~NAME~-data\n        dnsPolicy: ClusterFirst\n        restartPolicy: Always\n        serviceAccountName: ~NAME~\n        volumes:\n        - emptyDir:\n            medium: \"\"\n          name: ~NAME~-data\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    annotations:\n      serviceaccounts.openshift.io/oauth-redirectreference.jenkins: '{\"kind\":\"OAuthRedirectReference\",\"apiVersion\":\"v1\",\"reference\":{\"kind\":\"Route\",\"name\":\"~NAME~\"}}'\n    name: ~NAME~\n- apiVersion: v1\n  groupNames: null\n  kind: RoleBinding\n  metadata:\n    name: ~NAME~_edit\n  roleRef:\n    name: edit\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n- kind: Service\n  apiVersion: v1\n  metadata:\n    name: ~NAME~-jnlp\n  spec:\n    ports:\n    - name: agent\n      nodePort: 0\n      port: 50000\n      protocol: TCP\n      targetPort: 50000\n    selector:\n      name: ~NAME~\n    sessionAffinity: None\n    type: ClusterIP\n- kind: Service\n  apiVersion: v1\n  metadata:\n    annotations:\n      service.alpha.openshift.io/dependencies: '[{\"name\": \"~NAME~-jnlp\", \"namespace\": \"\", \"kind\": \"Service\"}]'\n      service.openshift.io/infrastructure: \"true\"\n    name: ~NAME~\n  spec:\n    ports:\n    - name: web\n      nodePort: 0\n      port: 80\n      protocol: TCP\n      targetPort: 8080\n    selector:\n      name: ~NAME~\n    sessionAffinity: None\n    type: ClusterIP\n"
    },
    "elasticsearch": {
      "URL": "docker.elastic.co/elasticsearch",
      "image": "elasticsearch-oss",
      "tag": "6.7.0",
      "storage": "4Gi",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: RoleBinding\n  apiVersion: authorization.openshift.io/v1\n  metadata:\n    name: ~NAME~-view\n    namespace: ~PROJECT~\n  roleRef:\n    kind: Role\n    name: view\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source        \n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n  spec:\n    accessModes:\n    - ReadWriteOnce \n    resources:\n       requests:\n         storage: ~STORAGE~\n    ~VOLUME~\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template: \n      metadata:\n        labels: \n          name: ~NAME~\n        name: ~NAME~\n      spec:\n        serviceAccountName: ~NAME~\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          image: ~IMAGE_STREAM~\n          readinessProbe:\n            httpGet:\n              path: /_cluster/health\n              port: 9200\n            initialDelaySeconds: 5\n          livenessProbe:\n            httpGet:\n              path: /_cluster/health?local=true\n              port: 9200\n            initialDelaySeconds: 90\n          env:\n            - name: NODE_DATA\n              value: 'false'\n            - name: NODE_MASTER\n              value: 'false'\n            - name: DISCOVERY_SERVICE\n              value: elasticsearch-discovery\n            - name: PROCESSORS\n              valueFrom:\n                resourceFieldRef:\n                  divisor: '0'\n                  resource: limits.cpu\n            - name: ES_JAVA_OPTS\n              value: \"-Djava.net.preferIPv4Stack=true -Xms512m -Xmx512m  \"\n            - name: MINIMUM_MASTER_NODES\n              value: '2'\n            - name: TAKE_FILE_OWNERSHIP\n              value: 'true'\n          volumeMounts:\n            - mountPath: /usr/share/elasticsearch/data/\n              name: ~NAME~\n        volumes:\n          - name: ~NAME~\n            namespace: ~PROJECT~\n            persistentVolumeClaim:\n              claimName: ~NAME~\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    type: LoadBalancer\n    ports:\n      - name: rest\n        port: 8080\n        targetPort: 8080\n      - name: sql\n        port: 10800\n        targetPort: 10800\n      - name: thinclients\n        port: 10900\n        targetPort: 10900\n    # Optional - remove 'sessionAffinity' property if the Ignite cluster\n    # and applications deployed within Kubernetes\n    sessionAffinity: ClientIP   \n    selector:\n      name: ~NAME~\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n"
    },
    "telegraf": {
      "URL": "docker.io",
      "image": "telegraf",
      "tag": "1.14-alpine",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: RoleBinding\n  apiVersion: authorization.openshift.io/v1\n  metadata:\n    name: ~NAME~-view\n    namespace: ~PROJECT~\n  roleRef:\n    kind: Role\n    name: view\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source        \n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template: \n      metadata:\n        labels: \n          name: ~NAME~\n        name: ~NAME~\n      spec:\n        serviceAccountName: ~NAME~\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          image: ~IMAGE_STREAM~\n          env:\n          - name: HOSTNAME\n            value: telegraf-polling-service\n          volumeMounts:\n          - name: config-volume\n            mountPath: /etc/telegraf\n        volumes:\n          - name: config-volume\n            configMap:\n              name: ~NAME~\n    selector:\n      name: ~NAME~\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    type: ClusterIP\n    ports:\n    - port: 8888\n      targetPort: 8888\n      name: \"health\"\n    - port: 8125\n      targetPort: 8125\n      protocol: \"UDP\"\n      name: \"statsd\"\n    selector:\n      name: ~NAME~\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: ConfigMap\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  data:\n    telegraf.conf: |+    \n      [agent]\n        collection_jitter = \"0s\"\n        debug = false\n        flush_interval = \"10s\"\n        flush_jitter = \"0s\"\n        hostname = \"$HOSTNAME\"\n        interval = \"10s\"\n        logfile = \"\"\n        metric_batch_size = 1000\n        metric_buffer_limit = 10000\n        omit_hostname = false\n        precision = \"\"\n        quiet = false\n        round_interval = true\n      [[processors.enum]]\n        [[processors.enum.mapping]]\n          dest = \"status_code\"\n          field = \"status\"\n          [processors.enum.mapping.value_mappings]\n              critical = 3\n              healthy = 1\n              problem = 2\n      [[outputs.prometheus_client]]\n        listen = \":9273\"\n        path = \"/metrics\"\n      [[inputs.internal]]\n        collect_memstats = false\n      [[inputs.influxdb_listener]]\n        service_address = \":8888\"\n"
    },
    "prometheus-alertmanager": {
      "URL": "docker.io/prom",
      "image": "alertmanager",
      "tag": "v0.20.0",
      "storage": "8Gi",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: RoleBinding\n  apiVersion: authorization.openshift.io/v1\n  metadata:\n    name: ~NAME~-view\n    namespace: ~PROJECT~\n  roleRef:\n    kind: Role\n    name: view\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source        \n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n  spec:\n    accessModes:\n    - ReadWriteOnce \n    resources:\n       requests:\n         storage: ~STORAGE~\n    ~VOLUME~\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template: \n      metadata:\n        labels: \n          name: ~NAME~\n        name: ~NAME~\n      spec:\n        serviceAccountName: ~NAME~\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          image: ~IMAGE_STREAM~\n          env:\n            - name: POD_IP\n              valueFrom:\n                fieldRef:\n                  apiVersion: v1\n                  fieldPath: status.podIP\n          args:\n            - --config.file=/etc/config/alertmanager.yml\n            - --storage.path=/data\n            - --cluster.advertise-address=$(POD_IP):6783\n            - --web.external-url=http://localhost:9093\n          ports:\n            - containerPort: 9093\n          readinessProbe:\n            httpGet:\n              path: /-/ready\n              port: 9093\n            initialDelaySeconds: 30\n            timeoutSeconds: 30\n          resources:\n            {}\n          volumeMounts:\n            - name: config-volume\n              mountPath: /etc/config\n            - name: storage-volume\n              mountPath: \"/data\"\n        volumes:\n          - name: config-volume\n            configMap:\n              name: ~NAME~\n          - name: storage-volume\n            namespace: ~PROJECT~\n            persistentVolumeClaim:\n              claimName: ~NAME~\n    selector:\n      name: ~NAME~\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    ports:\n      - name: http\n        port: 80\n        protocol: TCP\n        targetPort: 9093\n    selector:\n      name: ~NAME~\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: ConfigMap\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  data:\n    alertmanager.yml: |\n      global: {}\n      receivers:\n      - name: default-receiver\n      route:\n        group_interval: 5m\n        group_wait: 10s\n        receiver: default-receiver\n        repeat_interval: 3h\n"
    },
    "prometheus": {
      "URL": "docker.io/prom",
      "image": "prometheus",
      "tag": "v2.16.0",
      "storage": "200Mi",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: RoleBinding\n  apiVersion: authorization.openshift.io/v1\n  metadata:\n    name: ~NAME~-view\n    namespace: ~PROJECT~\n  roleRef:\n    kind: Role\n    name: view\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source        \n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n  spec:\n    accessModes:\n    - ReadWriteOnce \n    resources:\n       requests:\n         storage: ~STORAGE~\n    ~VOLUME~\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template: \n      metadata:\n        labels: \n          name: ~NAME~\n        name: ~NAME~\n      spec:\n        serviceAccountName: ~NAME~\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          image: ~IMAGE_STREAM~\n          args:\n            - --storage.tsdb.retention.time=15d\n            - --config.file=/etc/config/prometheus.yml\n            - --storage.tsdb.path=/data\n            - --web.console.libraries=/etc/prometheus/console_libraries\n            - --web.console.templates=/etc/prometheus/consoles\n            - --web.enable-lifecycle\n          ports:\n            - containerPort: 9090\n          readinessProbe:\n            httpGet:\n              path: /-/ready\n              port: 9090\n            initialDelaySeconds: 30\n            timeoutSeconds: 30\n            failureThreshold: 3\n            successThreshold: 1\n          livenessProbe:\n            httpGet:\n              path: /-/healthy\n              port: 9090\n            initialDelaySeconds: 30\n            timeoutSeconds: 30\n            failureThreshold: 3\n            successThreshold: 1\n          resources:\n            {}\n          volumeMounts:\n            - name: config-volume\n              mountPath: /etc/config\n            - mountPath: /data\n              name: storage-volume\n        volumes:\n          - name: config-volume\n            configMap:\n              name: ~NAME~\n          - name: storage-volume\n            namespace: ~PROJECT~\n            persistentVolumeClaim:\n              claimName: ~NAME~\n    selector:\n      name: ~NAME~\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    ports:\n      - name: http\n        port: 80\n        protocol: TCP\n        targetPort: 9090\n    selector:\n      name: ~NAME~\n    sessionAffinity: None\n    type: \"ClusterIP\"\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: ConfigMap\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  data:\n    alerting_rules.yml: |\n      {}\n    alerts: |\n      {}\n    prometheus.yml: |\n      global:\n        evaluation_interval: 1m\n        scrape_interval: 1m\n        scrape_timeout: 10s\n      rule_files:\n      - /etc/config/recording_rules.yml\n      - /etc/config/alerting_rules.yml\n      - /etc/config/rules\n      - /etc/config/alerts\n      scrape_configs:\n      - job_name: prometheus\n        static_configs:\n        - targets:\n          - localhost:9090\n      - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n        job_name: kubernetes-apiservers\n        kubernetes_sd_configs:\n        - role: endpoints\n        relabel_configs:\n        - action: keep\n          regex: default;kubernetes;https\n          source_labels:\n          - __meta_kubernetes_namespace\n          - __meta_kubernetes_service_name\n          - __meta_kubernetes_endpoint_port_name\n        scheme: https\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          insecure_skip_verify: true\n      - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n        job_name: kubernetes-nodes\n        kubernetes_sd_configs:\n        - role: node\n        relabel_configs:\n        - action: labelmap\n          regex: __meta_kubernetes_node_label_(.+)\n        - replacement: kubernetes.default.svc:443\n          target_label: __address__\n        - regex: (.+)\n          replacement: /api/v1/nodes/$1/proxy/metrics\n          source_labels:\n          - __meta_kubernetes_node_name\n          target_label: __metrics_path__\n        scheme: https\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          insecure_skip_verify: true\n      - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n        job_name: kubernetes-nodes-cadvisor\n        kubernetes_sd_configs:\n        - role: node\n        relabel_configs:\n        - action: labelmap\n          regex: __meta_kubernetes_node_label_(.+)\n        - replacement: kubernetes.default.svc:443\n          target_label: __address__\n        - regex: (.+)\n          replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor\n          source_labels:\n          - __meta_kubernetes_node_name\n          target_label: __metrics_path__\n        scheme: https\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          insecure_skip_verify: true\n      - job_name: kubernetes-service-endpoints\n        kubernetes_sd_configs:\n        - role: endpoints\n        relabel_configs:\n        - action: keep\n          regex: true\n          source_labels:\n          - __meta_kubernetes_service_annotation_prometheus_io_scrape\n        - action: replace\n          regex: (https?)\n          source_labels:\n          - __meta_kubernetes_service_annotation_prometheus_io_scheme\n          target_label: __scheme__\n        - action: replace\n          regex: (.+)\n          source_labels:\n          - __meta_kubernetes_service_annotation_prometheus_io_path\n          target_label: __metrics_path__\n        - action: replace\n          regex: ([^:]+)(?::d+)?;(d+)\n          replacement: $1:$2\n          source_labels:\n          - __address__\n          - __meta_kubernetes_service_annotation_prometheus_io_port\n          target_label: __address__\n        - action: labelmap\n          regex: __meta_kubernetes_service_label_(.+)\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_namespace\n          target_label: kubernetes_namespace\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_service_name\n          target_label: kubernetes_name\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_pod_node_name\n          target_label: kubernetes_node\n      - job_name: kubernetes-service-endpoints-slow\n        kubernetes_sd_configs:\n        - role: endpoints\n        relabel_configs:\n        - action: keep\n          regex: true\n          source_labels:\n          - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow\n        - action: replace\n          regex: (https?)\n          source_labels:\n          - __meta_kubernetes_service_annotation_prometheus_io_scheme\n          target_label: __scheme__\n        - action: replace\n          regex: (.+)\n          source_labels:\n          - __meta_kubernetes_service_annotation_prometheus_io_path\n          target_label: __metrics_path__\n        - action: replace\n          regex: ([^:]+)(?::d+)?;(d+)\n          replacement: $1:$2\n          source_labels:\n          - __address__\n          - __meta_kubernetes_service_annotation_prometheus_io_port\n          target_label: __address__\n        - action: labelmap\n          regex: __meta_kubernetes_service_label_(.+)\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_namespace\n          target_label: kubernetes_namespace\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_service_name\n          target_label: kubernetes_name\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_pod_node_name\n          target_label: kubernetes_node\n        scrape_interval: 5m\n        scrape_timeout: 30s\n      - honor_labels: true\n        job_name: prometheus-pushgateway\n        kubernetes_sd_configs:\n        - role: service\n        relabel_configs:\n        - action: keep\n          regex: pushgateway\n          source_labels:\n          - __meta_kubernetes_service_annotation_prometheus_io_probe\n      - job_name: kubernetes-services\n        kubernetes_sd_configs:\n        - role: service\n        metrics_path: /probe\n        params:\n          module:\n          - http_2xx\n        relabel_configs:\n        - action: keep\n          regex: true\n          source_labels:\n          - __meta_kubernetes_service_annotation_prometheus_io_probe\n        - source_labels:\n          - __address__\n          target_label: __param_target\n        - replacement: blackbox\n          target_label: __address__\n        - source_labels:\n          - __param_target\n          target_label: instance\n        - action: labelmap\n          regex: __meta_kubernetes_service_label_(.+)\n        - source_labels:\n          - __meta_kubernetes_namespace\n          target_label: kubernetes_namespace\n        - source_labels:\n          - __meta_kubernetes_service_name\n          target_label: kubernetes_name\n      - job_name: kubernetes-pods\n        kubernetes_sd_configs:\n        - role: pod\n        relabel_configs:\n        - action: keep\n          regex: true\n          source_labels:\n          - __meta_kubernetes_pod_annotation_prometheus_io_scrape\n        - action: replace\n          regex: (.+)\n          source_labels:\n          - __meta_kubernetes_pod_annotation_prometheus_io_path\n          target_label: __metrics_path__\n        - action: replace\n          regex: ([^:]+)(?::d+)?;(d+)\n          replacement: $1:$2\n          source_labels:\n          - __address__\n          - __meta_kubernetes_pod_annotation_prometheus_io_port\n          target_label: __address__\n        - action: labelmap\n          regex: __meta_kubernetes_pod_label_(.+)\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_namespace\n          target_label: kubernetes_namespace\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_pod_name\n          target_label: kubernetes_pod_name\n      - job_name: kubernetes-pods-slow\n        kubernetes_sd_configs:\n        - role: pod\n        relabel_configs:\n        - action: keep\n          regex: true\n          source_labels:\n          - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow\n        - action: replace\n          regex: (.+)\n          source_labels:\n          - __meta_kubernetes_pod_annotation_prometheus_io_path\n          target_label: __metrics_path__\n        - action: replace\n          regex: ([^:]+)(?::d+)?;(d+)\n          replacement: $1:$2\n          source_labels:\n          - __address__\n          - __meta_kubernetes_pod_annotation_prometheus_io_port\n          target_label: __address__\n        - action: labelmap\n          regex: __meta_kubernetes_pod_label_(.+)\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_namespace\n          target_label: kubernetes_namespace\n        - action: replace\n          source_labels:\n          - __meta_kubernetes_pod_name\n          target_label: kubernetes_pod_name\n        scrape_interval: 5m\n        scrape_timeout: 30s\n      alerting:\n        alertmanagers:\n        - kubernetes_sd_configs:\n            - role: pod\n          tls_config:\n            ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n          relabel_configs:\n          - source_labels: [__meta_kubernetes_namespace]\n            regex: ~NAME~\n            action: keep\n          - source_labels: [__meta_kubernetes_pod_label_app]\n            regex: prometheus\n            action: keep\n          - source_labels: [__meta_kubernetes_pod_label_component]\n            regex: alertmanager\n            action: keep\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_probe]\n            regex: .*\n            action: keep\n          - source_labels: [__meta_kubernetes_pod_container_port_number]\n            regex:\n            action: drop\n    recording_rules.yml: |\n      {}\n    rules: |\n      {}\n"
    },
    "kube-state-metrics": {
      "URL": "quay.io/coreos",
      "image": "kube-state-metrics",
      "tag": "v1.9.5",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ClusterRole\n  apiVersion: rbac.authorization.k8s.io/v1beta1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  rules:\n  - apiGroups: [\"certificates.k8s.io\"]\n    resources:\n    - certificatesigningrequests\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - configmaps\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"batch\"]\n    resources:\n    - cronjobs\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"extensions\", \"apps\"]\n    resources:\n    - daemonsets\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"extensions\", \"apps\"]\n    resources:\n    - deployments\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - endpoints\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"autoscaling\"]\n    resources:\n    - horizontalpodautoscalers\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"extensions\", \"networking.k8s.io\"]\n    resources:\n    - ingresses\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"batch\"]\n    resources:\n    - jobs\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - limitranges\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - namespaces\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - nodes\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - persistentvolumeclaims\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - persistentvolumes\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"policy\"]\n    resources:\n      - poddisruptionbudgets\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - pods\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"extensions\", \"apps\"]\n    resources:\n    - replicasets\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - replicationcontrollers\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - resourcequotas\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - secrets\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources:\n    - services\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"apps\"]\n    resources:\n    - statefulsets\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"storage.k8s.io\"]\n    resources:\n      - storageclasses\n    verbs: [\"list\", \"watch\"]\n- kind: ClusterRoleBinding\n  apiVersion: rbac.authorization.k8s.io/v1beta1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  roleRef:\n    kind: ClusterRole\n    name: ~NAME~\n    namespace: ~PROJECT~\n    apiGroup: rbac.authorization.k8s.io\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source        \n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template: \n      metadata:\n        labels: \n          name: ~NAME~\n        name: ~NAME~\n      spec:\n        hostNetwork: false\n        serviceAccountName: ~NAME~\n        securityContext:\n          fsGroup: 65534\n          runAsUser: 65534\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          args:\n          - --collectors=certificatesigningrequests\n          - --collectors=configmaps\n          - --collectors=cronjobs\n          - --collectors=daemonsets\n          - --collectors=deployments\n          - --collectors=endpoints\n          - --collectors=horizontalpodautoscalers\n          - --collectors=ingresses\n          - --collectors=jobs\n          - --collectors=limitranges\n          - --collectors=namespaces\n          - --collectors=nodes\n          - --collectors=persistentvolumeclaims\n          - --collectors=persistentvolumes\n          - --collectors=poddisruptionbudgets\n          - --collectors=pods\n          - --collectors=replicasets\n          - --collectors=replicationcontrollers\n          - --collectors=resourcequotas\n          - --collectors=secrets\n          - --collectors=services\n          - --collectors=statefulsets\n          - --collectors=storageclasses\n          imagePullPolicy: IfNotPresent\n          image: ~IMAGE_STREAM~\n          ports:\n          - containerPort: 8080\n          livenessProbe:\n            httpGet:\n              path: /healthz\n              port: 8080\n            initialDelaySeconds: 5\n            timeoutSeconds: 5\n          readinessProbe:\n            httpGet:\n              path: /\n              port: 8080\n            initialDelaySeconds: 5\n            timeoutSeconds: 5\n    selector:\n      name: ~NAME~\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    type: \"ClusterIP\"\n    ports:\n    - name: \"http\"\n      protocol: TCP\n      port: 8080\n      targetPort: 8080\n    selector:\n      name: ~NAME~\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n"
    },
    "pushgateway": {
      "URL": "docker.io/prom",
      "image": "pushgateway",
      "tag": "v1.0.1",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: RoleBinding\n  apiVersion: authorization.openshift.io/v1\n  metadata:\n    name: ~NAME~-view\n    namespace: ~PROJECT~\n  roleRef:\n    kind: Role\n    name: view\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source        \n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template: \n      metadata:\n        labels: \n          name: ~NAME~\n        name: ~NAME~\n      spec:\n        serviceAccountName: ~NAME~\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          image: ~IMAGE_STREAM~\n          ports:\n            - containerPort: 9091\n          livenessProbe:\n            httpGet:\n              path: /-/healthy\n              port: 9091\n            initialDelaySeconds: 10\n            timeoutSeconds: 10\n          readinessProbe:\n            httpGet:\n              path: /-/ready\n              port: 9091\n            initialDelaySeconds: 10\n            timeoutSeconds: 10\n          resources:\n            {}\n    selector:\n      name: ~NAME~\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    selector:\n      name: ~NAME~\n    ports:\n      - name: http\n        port: 9091\n        protocol: TCP\n        targetPort: 9091\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n"
    },
    "grafana": {
      "URL": "grafana",
      "image": "grafana",
      "tag": "6.6.2",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: RoleBinding\n  apiVersion: authorization.openshift.io/v1\n  metadata:\n    name: ~NAME~-view\n    namespace: ~PROJECT~\n  roleRef:\n    kind: Role\n    name: view\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: PodSecurityPolicy\n  apiVersion: policy/v1beta1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n    annotations:\n      seccomp.security.alpha.kubernetes.io/allowedProfileNames: 'docker/default'\n      seccomp.security.alpha.kubernetes.io/defaultProfileName:  'docker/default'\n      apparmor.security.beta.kubernetes.io/allowedProfileNames: 'runtime/default'\n      apparmor.security.beta.kubernetes.io/defaultProfileName:  'runtime/default'\n  spec:\n    privileged: false\n    allowPrivilegeEscalation: false\n    requiredDropCapabilities:\n      # Default set from Docker, without DAC_OVERRIDE or CHOWN\n      - FOWNER\n      - FSETID\n      - KILL\n      - SETGID\n      - SETUID\n      - SETPCAP\n      - NET_BIND_SERVICE\n      - NET_RAW\n      - SYS_CHROOT\n      - MKNOD\n      - AUDIT_WRITE\n      - SETFCAP\n    volumes:\n      - 'configMap'\n      - 'emptyDir'\n      - 'projected'\n      - 'secret'\n      - 'downwardAPI'\n      - 'persistentVolumeClaim'\n    hostNetwork: false\n    hostIPC: false\n    hostPID: false\n    runAsUser:\n      rule: 'RunAsAny'\n    seLinux:\n      rule: 'RunAsAny'\n    supplementalGroups:\n      rule: 'RunAsAny'\n    fsGroup:\n      rule: 'RunAsAny'\n    readOnlyRootFilesystem: false\n- kind: Secret\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  type: Opaque\n  stringData:\n    admin-user: \"admin\"\n    admin-password: \"~NAME~\"\n    ldap-toml: \"\"\n- kind: Role\n  apiVersion: rbac.authorization.k8s.io/v1beta1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  rules:\n  - apiGroups:      ['extensions']\n    resources:      ['podsecuritypolicies']\n    verbs:          ['use']\n    resourceNames:  [~NAME~]\n- kind: RoleBinding\n  apiVersion: rbac.authorization.k8s.io/v1beta1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  roleRef:\n    apiGroup: rbac.authorization.k8s.io\n    kind: Role\n    name: ~NAME~\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template:\n      metadata:\n        labels:\n          app.kubernetes.io/name: ~NAME~\n          app.kubernetes.io/instance: ~PROJECT~\n        annotations:\n          checksum/config: 4475028f2c9539fd7734add184328dab2f3276bb67234eaa341bf31148a57a95\n          checksum/dashboards-json-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b\n          checksum/sc-dashboard-provider-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b\n          checksum/secret: ce5751f7f7d101eaf061a9daac6dcc70a2aced1e3099af5448c3fe23c66dd633\n      spec:\n        serviceAccountName: ~NAME~\n        securityContext:\n          fsGroup: 472\n          runAsUser: 472\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          image: ~IMAGE_STREAM~\n          env:\n            - name: GF_SECURITY_ADMIN_USER\n              valueFrom:\n                secretKeyRef:\n                  name: ~NAME~\n                  key: admin-user\n            - name: GF_SECURITY_ADMIN_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: ~NAME~\n                  key: admin-password\n          ports:\n            - name: service\n              containerPort: 80\n              protocol: TCP\n            - name: grafana\n              containerPort: 3000\n              protocol: TCP\n          volumeMounts:\n            - name: ~NAME~-config\n              namespace: ~PROJECT~\n              mountPath: \"/etc/grafana/grafana.ini\"\n              subPath: grafana.ini\n            - name: ~NAME~-storage\n              mountPath: \"/var/lib/grafana\"\n          livenessProbe:\n            failureThreshold: 10\n            httpGet:\n              path: /api/health\n              port: 3000\n            initialDelaySeconds: 60\n            timeoutSeconds: 30\n          readinessProbe:\n            httpGet:\n              path: /api/health\n              port: 3000\n          resources:\n            {}\n        volumes:\n          - name: ~NAME~-config\n            namespace: ~PROJECT~\n            configMap:\n              name: ~NAME~\n          - name: ~NAME~-storage\n            emptyDir: {}\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    type: ClusterIP\n    ports:\n      - name: service\n        port: 80\n        protocol: TCP\n        targetPort: 3000\n    selector:\n      app.kubernetes.io/name: ~NAME~\n      app.kubernetes.io/instance: ~PROJECT~\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: ConfigMap\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  data:\n    grafana.ini: |\n      [analytics]\n      check_for_updates = true\n      [grafana_net]\n      url = https://grafana.net\n      [log]\n      mode = console\n      [paths]\n      data = /var/lib/grafana/data\n      logs = /var/log/grafana\n      plugins = /var/lib/grafana/plugins\n      provisioning = /etc/grafana/provisioning\n"
    },
    "ignite": {
      "URL": "docker.io/gridgain",
      "image": "community",
      "tag": "8.7.14",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: RoleBinding\n  apiVersion: authorization.openshift.io/v1\n  metadata:\n    name: ~NAME~-view\n    namespace: ~PROJECT~\n  roleRef:\n    kind: Role\n    name: view\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source\n~PERSISTENCE_START~\n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~-work\n  spec:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: ~STORAGE~\n    ~VOLUME~\n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~-wal\n  spec:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: ~STORAGE~\n    ~VOLUME~\n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~-walarchive\n  spec:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: ~STORAGE~\n    ~VOLUME~\n~PERSISTENCE_END~\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template: \n      metadata:\n        labels: \n          name: ~NAME~\n        name: ~NAME~\n      spec:\n        serviceAccountName: ~NAME~\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          image: ~IMAGE_STREAM~\n          env:\n          - name: OPTION_LIBS\n            value: ignite-kubernetes,ignite-rest-http\n          - name: CONFIG_URI\n            value: file:/etc/opt/hpe-5g/ignite/igniteConfig.xml\n~PERSISTENCE_START~\n          - name: JVM_OPTS\n            value: \"-DIGNITE_WAL_MMAP=false\"\n~PERSISTENCE_END~\n          ports:\n          # Ports to open.\n          # Might be optional depending on your Kubernetes environment.\n          - containerPort: 11211 # REST port number.\n          - containerPort: 47100 # communication SPI port number.\n          - containerPort: 47500 # discovery SPI port number.\n          - containerPort: 49112 # JMX port number.\n          - containerPort: 10800 # SQL port number.\n          - containerPort: 10900 # Thin clients port number.\n          volumeMounts:\n            - name: ~NAME~\n              namespace: ~PROJECT~\n              mountPath: /etc/opt/hpe-5g/ignite/\n~PERSISTENCE_START~\n            - mountPath: /gridgain/work\n              name: ~NAME~-work\n            - mountPath: /gridgain/wal\n              name: ~NAME~-wal\n            - mountPath: /gridgain/walarchive\n              name: ~NAME~-walarchive\n~PERSISTENCE_END~\n        volumes:\n          - name: ~NAME~\n            namespace: ~PROJECT~\n            configMap:\n              name: ~NAME~\n~PERSISTENCE_START~\n          - name: ~NAME~-work\n            persistentVolumeClaim:\n              claimName: ~NAME~-work\n          - name: ~NAME~-wal\n            persistentVolumeClaim:\n              claimName: ~NAME~-wal\n          - name: ~NAME~-walarchive\n            persistentVolumeClaim:\n              claimName: ~NAME~-walarchive\n~PERSISTENCE_END~\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    type: LoadBalancer\n    ports:\n      - name: rest\n        port: 8080\n        targetPort: 8080\n      - name: sql\n        port: 10800\n        targetPort: 10800\n      - name: thinclients\n        port: 10900\n        targetPort: 10900\n    # Optional - remove 'sessionAffinity' property if the Ignite cluster\n    # and applications deployed within Kubernetes\n    sessionAffinity: ClientIP   \n    selector:\n      name: ~NAME~\n      deploymentconfig: ~NAME~\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: ConfigMap\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  data:\n    igniteConfig.xml: |+\n      <beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\" http://www.springframework.org/schema/beans  http://www.springframework.org/schema/beans/spring-beans-3.1.xsd\">\n       <bean id=\"ignite.cfg\" class=\"org.apache.ignite.configuration.IgniteConfiguration\">\n~PERSISTENCE_START~\n       <property name=\"workDirectory\" value=\"/gridgain/work\"/>\n           <property name=\"dataStorageConfiguration\">\n               <bean class=\"org.apache.ignite.configuration.DataStorageConfiguration\">\n                   <property name=\"defaultDataRegionConfiguration\">\n                       <bean class=\"org.apache.ignite.configuration.DataRegionConfiguration\">\n                           <property name=\"persistenceEnabled\" value=\"true\"/>\n                       </bean>\n                   </property>\n                   <property name=\"walPath\" value=\"/gridgain/wal\"/>\n                   <property name=\"walArchivePath\" value=\"/gridgain/walarchive\"/>\n               </bean>\n           </property>\n~PERSISTENCE_END~\n         <property name=\"discoverySpi\">\n            <bean class=\"org.apache.ignite.spi.discovery.tcp.TcpDiscoverySpi\">\n              <property name=\"ipFinder\">\n                 <bean class=\"org.apache.ignite.spi.discovery.tcp.ipfinder.kubernetes.TcpDiscoveryKubernetesIpFinder\">\n                 <property name=\"namespace\" value=\"~PROJECT~\"/>\n                 <property name=\"serviceName\" value=\"~NAME~\"/>\n                 <property name=\"masterUrl\" value=\"https://#{systemEnvironment['KUBERNETES_SERVICE_HOST']}:443\"/>\n                 </bean>\n              </property>\n            </bean>\n         </property>\n        </bean>\n       </beans>\n"
    },
    "redis": {
      "URL": "docker.io/bitnami",
      "image": "redis",
      "tag": "latest",
      "storage": "100Mi",
      "template": "\n- kind: Secret\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  name: ~NAME~\n  stringData:\n    database-password: ~NAME~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    ports:\n    - name: redis\n      nodePort: 0\n      port: 6379\n      protocol: TCP\n      targetPort: 6379\n    selector:\n      name: ~NAME~\n      deploymentconfig: ~NAME~\n    sessionAffinity: None\n    type: ClusterIP\n  status:\n    loadBalancer: {}\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n  spec:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: ~STORAGE~\n    ~VOLUME~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    annotations:\n      template.alpha.openshift.io/wait-for-ready: 'true'\n    name: ~NAME~\n  spec:\n    replicas: ~REPLICAS~\n    selector:\n      name: ~NAME~\n    strategy:\n      type: Recreate\n    template:\n      metadata:\n        labels:\n          name: ~NAME~\n      spec:\n        containers:\n        - capabilities: {}\n          env:\n          - name: REDIS_PORT\n            value: \"6379\"\n\n          - name: REDIS_PASSWORD\n            valueFrom:\n              secretKeyRef:\n                key: database-password\n                name: ~NAME~\n          image: ~IMAGE_STREAM~\n          livenessProbe:\n            initialDelaySeconds: 30\n            tcpSocket:\n              port: 6379\n            timeoutSeconds: 1\n          name: redis\n          ports:\n          - containerPort: 6379\n            protocol: TCP\n          readinessProbe:\n            exec:\n              command:\n              - \"/bin/bash\"\n              - \"-i\"\n              - \"-c\"\n              - \"test \\\"$(redis-cli -h 127.0.0.1 -a ~NAME~ ping)\\\" == \\\"PONG\\\"\"\n            initialDelaySeconds: 5\n            timeoutSeconds: 1\n          resources:\n            limits:\n              memory: ~STORAGE~\n          securityContext:\n            capabilities: {}\n            privileged: false\n          terminationMessagePath: \"/dev/termination-log\"\n          volumeMounts:\n          - mountPath: \"/var/lib/redis/data\"\n            name: \"~NAME~-data\"\n        dnsPolicy: ClusterFirst\n        restartPolicy: Always\n        volumes:\n        - name: \"~NAME~-data\"\n          persistentVolumeClaim:\n            claimName: ~NAME~\n  status: {}\n"
    },
    "redis-nopwd": {
      "URL": "docker.io/bitnami",
      "image": "redis",
      "tag": "latest",
      "storage": "100Mi",
      "template": "\n- kind: Secret\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  name: ~NAME~\n  stringData:\n    database-password: ~NAME~\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    ports:\n    - name: redis\n      nodePort: 0\n      port: 6379\n      protocol: TCP\n      targetPort: 6379\n    selector:\n      name: ~NAME~\n      deploymentconfig: ~NAME~\n    sessionAffinity: None\n    type: ClusterIP\n  status:\n    loadBalancer: {}\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n  spec:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: ~STORAGE~\n    ~VOLUME~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    annotations:\n      template.alpha.openshift.io/wait-for-ready: 'true'\n    name: ~NAME~\n  spec:\n    replicas: ~REPLICAS~\n    selector:\n      name: ~NAME~\n    strategy:\n      type: Recreate\n    template:\n      metadata:\n        labels:\n          name: ~NAME~\n      spec:\n        containers:\n        - capabilities: {}\n          env:\n          - name: REDIS_PORT\n            value: \"6379\"\n\n          - name: ALLOW_EMPTY_PASSWORD\n            value: \"true\"\n          image: ~IMAGE_STREAM~\n          livenessProbe:\n            initialDelaySeconds: 30\n            tcpSocket:\n              port: 6379\n            timeoutSeconds: 1\n          name: redis\n          ports:\n          - containerPort: 6379\n            protocol: TCP\n          readinessProbe:\n            exec:\n              command:\n              - \"/bin/bash\"\n              - \"-i\"\n              - \"-c\"\n              - \"test \\\"$(redis-cli -h 127.0.0.1 -a ~NAME~ ping)\\\" == \\\"PONG\\\"\"\n            initialDelaySeconds: 5\n            timeoutSeconds: 1\n          resources:\n            limits:\n              memory: ~STORAGE~\n          securityContext:\n            capabilities: {}\n            privileged: false\n          terminationMessagePath: \"/dev/termination-log\"\n          volumeMounts:\n          - mountPath: \"/var/lib/redis/data\"\n            name: \"~NAME~-data\"\n        dnsPolicy: ClusterFirst\n        restartPolicy: Always\n        volumes:\n        - name: \"~NAME~-data\"\n          persistentVolumeClaim:\n            claimName: ~NAME~\n  status: {}\n"
    },
    "influxdb": {
      "URL": "docker.io/bitnami",
      "image": "influxdb",
      "tag": "1.7.10",
      "storage": "1Gi",
      "template": "\n- kind: Secret\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  name: ~NAME~\n  stringData:\n    admin-user-password: ~NAME~\n  type: Opaque\n- kind: PersistentVolumeClaim\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n  spec:\n    accessModes:\n    - ReadWriteOnce\n    resources:\n      requests:\n        storage: ~STORAGE~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source\n- kind: Service\n  apiVersion: v1\n  metadata: \n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    type: ClusterIP\n    ports:\n      - port: 8086\n        targetPort: http\n        protocol: TCP\n        name: http\n        nodePort: null\n      - port: 8088\n        targetPort: rpc\n        protocol: TCP\n        name: rpc\n        nodePort: null\n    selector:\n        name: ~NAME~\n        deploymentconfig: ~NAME~\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    annotations:\n      template.alpha.openshift.io/wait-for-ready: 'true'\n    name: ~NAME~\n  spec:\n    replicas: ~REPLICAS~\n    selector:\n        name: ~NAME~\n    template:\n      metadata:\n        labels:\n          name: ~NAME~\n      spec:\n        containers:\n          - name: ~NAME~\n            image: ~IMAGE_STREAM~\n            imagePullPolicy: IfNotPresent\n            env:\n              - name: BITNAMI_DEBUG\n                value: \"false\"\n              - name: POD_IP\n                valueFrom:\n                  fieldRef:\n                    fieldPath: status.podIP\n              - name: INFLUXDB_HTTP_AUTH_ENABLED\n                value: \"false\"\n              - name: INFLUXDB_ADMIN_USER\n                value: \"admin\"\n              - name: INFLUXDB_ADMIN_USER_PASSWORD\n                valueFrom:\n                  secretKeyRef:\n                    name: ~NAME~\n                    key: admin-user-password\n              - name: INFLUXDB_DB\n                value: ~NAME~\n            ports:\n              - name: http\n                containerPort: 8086\n                protocol: TCP\n              - name: rpc\n                containerPort: 8088\n                protocol: TCP\n            livenessProbe:\n              exec:\n                command:\n                  - \"/bin/bash\"\n                  - \"-i\"\n                  - \"-c\"\n                  - \"INFLUX_USERNAME=\\\"$INFLUXDB_ADMIN_USER\\\" INFLUX_PASSWORD=\\\"$INFLUXDB_ADMIN_USER_PASSWORD\\\" timeout 29s influx -host $POD_IP -port 8086 -execute \\\"SHOW DATABASES\\\" \"\n              initialDelaySeconds: 180\n              periodSeconds: 45\n              timeoutSeconds: 30\n              successThreshold: 1\n              failureThreshold: 6\n            readinessProbe:\n              exec:\n                command:\n                  - \"/bin/bash\"\n                  - \"-i\"\n                  - \"-c\"\n                  - \"INFLUX_USERNAME=\\\"$INFLUXDB_ADMIN_USER\\\" INFLUX_PASSWORD=\\\"$INFLUXDB_ADMIN_USER_PASSWORD\\\" timeout 29s influx -host $POD_IP -port 8086 -execute \\\"SHOW DATABASES\\\" \"\n              initialDelaySeconds: 60\n              periodSeconds: 45\n              timeoutSeconds: 30\n              successThreshold: 1\n              failureThreshold: 6\n            resources:\n              limits: {}\n              requests: {}\n            volumeMounts:\n              - name: data\n                mountPath: /bitnami/influxdb\n        volumes:\n          - name: data\n            persistentVolumeClaim:\n              claimName: ~NAME~\n"
    },
    "fluentd": {
      "URL": "gcr.io/google-containers",
      "image": "fluentd-elasticsearch",
      "tag": "v2.4.0",
      "template": "\n- kind: ServiceAccount\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: RoleBinding\n  apiVersion: authorization.openshift.io/v1\n  metadata:\n    name: ~NAME~-view\n    namespace: ~PROJECT~\n  roleRef:\n    kind: Role\n    name: view\n  subjects:\n  - kind: ServiceAccount\n    name: ~NAME~\n    namespace: ~PROJECT~\n- kind: Role\n  apiVersion: rbac.authorization.k8s.io/v1beta1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  rules:\n  - apiGroups: ['extensions']\n    resources: ['podsecuritypolicies']\n    verbs:     ['use']\n    resourceNames:\n    - ~NAME~\n- kind: ImageStream\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    lookupPolicy:\n      local: false\n    tags:\n    - annotations:\n      from:\n        kind: DockerImage\n        name: ~IMAGE_STREAM~\n      generation: 1\n      importPolicy: {}\n      name: \"\"\n      referencePolicy:\n        type: Source\n- kind: DeploymentConfig\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    template: \n      metadata:\n        labels: \n          name: ~NAME~\n        name: ~NAME~\n      spec:\n        serviceAccountName: ~NAME~\n        terminationGracePeriodSeconds: 30\n        containers:\n        - name: ~NAME~\n          namespace: ~PROJECT~\n          image: ~IMAGE_STREAM~\n          imagePullPolicy: IfNotPresent\n          env:\n            - name: OUTPUT_HOST\n              value: \"elasticsearch-client.default.svc.cluster.local\"\n            - name: OUTPUT_PORT\n              value: \"9200\"\n            - name: OUTPUT_SCHEME\n              value: \"http\"\n            - name: OUTPUT_SSL_VERSION\n              value: \"TLSv1\"\n            - name: OUTPUT_BUFFER_CHUNK_LIMIT\n              value: \"2M\"\n            - name: OUTPUT_BUFFER_QUEUE_LIMIT\n              value: \"8\"\n          resources:\n              {}\n          ports:\n            - name: monitor-agent\n              containerPort: 24220\n              protocol: TCP\n            - name: http-input\n              containerPort: 9880\n              protocol: TCP\n          livenessProbe:\n            httpGet:\n              # Use percent encoding for query param.\n              # The value is {\"log\": \"health check\"}.\n              # the endpoint itself results in a new fluentd\n              # tag 'fluentd.pod-healthcheck'\n              path: /fluentd.pod.healthcheck?json=%7B%22log%22%3A+%22health+check%22%7D\n              port: 9880\n            initialDelaySeconds: 5\n            timeoutSeconds: 1\n          volumeMounts:\n            - name: ~NAME~-config\n              mountPath: /etc/fluent/config.d\n            - name: ~NAME~-buffer\n              mountPath: \"/var/log/fluentd-buffers\"\n        volumes:\n          - name: ~NAME~-config\n            configMap:\n              name: ~NAME~\n              defaultMode: 0777\n          - name: ~NAME~-buffer\n            emptyDir: {}\n    replicas: ~REPLICAS~\n- kind: Service\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n    annotations:\n      {}\n  spec:\n    type: ClusterIP\n    ports:\n      - name: monitor-agent\n        port: 24220\n        targetPort: 24220\n        protocol: TCP\n    selector:\n      name: ~NAME~\n- kind: Route\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    to:\n      kind: Service\n      name: ~NAME~\n- kind: ConfigMap\n  apiVersion: v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  data:\n    forward-input.conf: |-\n      <source>\n        @type forward\n        port 24224\n        bind 0.0.0.0\n      </source>\n      \n    general.conf: |-\n      # Prevent fluentd from handling records containing its own logs. Otherwise\n      # it can lead to an infinite loop, when error in sending one message generates\n      # another message which also fails to be sent and so on.\n      <match fluentd.**>\n        @type null\n      </match>\n      \n      # Used for health checking\n      <source>\n        @type http\n        port 9880\n        bind 0.0.0.0\n      </source>\n      \n      # Emits internal metrics to every minute, and also exposes them on port\n      # 24220. Useful for determining if an output plugin is retryring/erroring,\n      # or determining the buffer queue length.\n      <source>\n        @type monitor_agent\n        bind 0.0.0.0\n        port 24220\n        tag fluentd.monitor.metrics\n      </source>\n      \n    output.conf: |-\n      <match **>\n        @id elasticsearch\n        @type elasticsearch\n        @log_level info\n        include_tag_key true\n        # Replace with the host/port to your Elasticsearch cluster.\n        host \"#{ENV['OUTPUT_HOST']}\"\n        port \"#{ENV['OUTPUT_PORT']}\"\n        scheme \"#{ENV['OUTPUT_SCHEME']}\"\n        ssl_version \"#{ENV['OUTPUT_SSL_VERSION']}\"\n        logstash_format true\n        <buffer>\n        @type file\n      \tpath /var/log/fluentd-buffers/kubernetes.system.buffer\n      \tflush_mode interval\n      \tretry_type exponential_backoff\n      \tflush_thread_count 2\n      \tflush_interval 5s\n      \tretry_forever\n      \tretry_max_interval 30\n      \tchunk_limit_size \"#{ENV['OUTPUT_BUFFER_CHUNK_LIMIT']}\"\n      \tqueue_limit_length \"#{ENV['OUTPUT_BUFFER_QUEUE_LIMIT']}\"\n      \toverflow_action block\n        </buffer>\n      </match>\n      \n    system.conf: |-\n      <system>\n        root_dir /tmp/fluentd-buffers/\n      </system>\n"
    },
    "jaeger-product": {
      "template": "\n- kind: Jaeger\n  apiVersion: jaegertracing.io/v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n"
    },
    "cert-manager": {
      "template": "\n- kind: CertManager\n  apiVersion: operator.cert-manager.io/v1alpha1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec: {}\n"
    },
    "servicemeshoperator": {
      "template": "\n- kind: ServiceMeshControlPlane\n  apiVersion: maistra.io/v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    istio:\n      gateways:\n        istio-egressgateway:\n          autoscaleEnabled: false\n        istio-ingressgateway:\n          autoscaleEnabled: false\n      mixer:\n        policy:\n          autoscaleEnabled: false\n        telemetry:\n          autoscaleEnabled: false\n      pilot:\n        autoscaleEnabled: false\n        traceSampling: 100\n      kiali:\n        enabled: true\n      grafana:\n        enabled: true\n      tracing:\n        enabled: true\n        jaeger:\n          template: all-in-one\n"
    },
    "amq-streams": {
      "template": "\n- kind: Kafka\n  apiVersion: kafka.strimzi.io/v1beta1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    kafka:\n      version: 2.4.0\n      replicas: ~REPLICAS~\n      listeners:\n        plain: {}\n        tls: {}\n      config:\n        offsets.topic.replication.factor: 3\n        transaction.state.log.replication.factor: 3\n        transaction.state.log.min.isr: 2\n        log.message.format.version: '2.4'\n      storage:\n        type: ephemeral\n    zookeeper:\n      replicas: ~REPLICAS~\n      storage:\n        type: ephemeral\n    entityOperator:\n      topicOperator: {}\n      userOperator: {}\n"
    },
    "elasticsearch-operator": {
      "template": "\n- kind: Elasticsearch\n  apiVersion: logging.openshift.io/v1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    managementState: Managed\n    nodeSpec:\n      image: >-\n        registry.redhat.io/openshift4/ose-logging-elasticsearch5@sha256:7ec49695f518ffab41e97fd2eb3c6ce79a4237cf537f6202ee35dbebcbecf444\n      resources:\n        limits:\n          memory: 1Gi\n        requests:\n          memory: 512Mi\n    redundancyPolicy: SingleRedundancy\n    nodes:\n      - nodeCount: 1\n        roles:\n          - client\n          - data\n          - master\n"
    },
    "kiali-ossm": {
      "template": "\n- kind: MonitoringDashboard\n  apiVersion: monitoring.kiali.io/v1alpha1\n  metadata:\n    name: ~NAME~\n    namespace: ~PROJECT~\n  spec:\n    title: My App Dashboard\n    items:\n      - chart:\n        name: My App Processing Duration\n        unit: seconds\n        spans: 6\n        metricName: my_app_duration_seconds\n        dataType: histogram\n        aggregations:\n          - label: id\n            displayName: ID\n"
    },
    "grafana-operator": {
      "template": "\n- kind: OperatorGroup\n  apiVersion: operators.coreos.com/v1\n  metadata:\n    name: grafana-operator-~PROJECT~\n    namespace: ~PROJECT~\n  spec:\n    targetNamespaces:\n    - ~PROJECT~\n- kind: Subscription\n  apiVersion: operators.coreos.com/v1alpha1\n  metadata:\n    name: grafana-operator-~PROJECT~\n    namespace: ~PROJECT~\n  spec:\n    channel: alpha\n    installPlanApproval: Automatic\n    name: grafana-operator\n    source: community-operators\n    sourceNamespace: openshift-marketplace\n- kind: Grafana\n  apiVersion: integreatly.org/v1alpha1\n  metadata:\n    name: ~NAME~-grafana\n    namespace: ~PROJECT~\n  spec:\n    ingress:\n      enabled: true\n    config:\n      auth:\n        disable_signout_menu: true\n      auth.anonymous:\n        enabled: true\n      log:\n        level: warn\n        mode: console\n      security:\n        admin_password: secret\n        admin_user: root\n      dashboardLabelSelector:\n        - matchExpressions:\n          - key: app\n            operator: In\n            values:\n              - grafana\n- kind: GrafanaDataSource\n  apiVersion: integreatly.org/v1alpha1\n  metadata:\n    name: ~NAME~-grafanadatasource\n    namespace: ~PROJECT~\n  spec:\n    datasources:\n      - access: proxy\n        editable: true\n        isDefault: true\n        jsonData:\n          timeInterval: 5s\n        name: Prometheus\n        type: prometheus\n        url: 'http://prometheus-operated.~PROJECT~.svc.cluster.local:9090'\n        version: 1\n    name: example-datasources.yaml\n- kind: GrafanaDashboard\n  apiVersion: integreatly.org/v1alpha1\n  metadata:\n    name: ~NAME~-grafanadashboard\n    namespace: ~PROJECT~\n  spec:\n    json: |\n      {\n        \"id\": null,\n        \"title\": \"grafana CMS5G core stack Dashboard\",\n        \"tags\": [],\n        \"style\": \"dark\",\n        \"timezone\": \"browser\",\n        \"editable\": true,\n        \"hideControls\": false,\n        \"graphTooltip\": 1,\n        \"panels\": [],\n        \"time\": {\n          \"from\": \"now-6h\",\n          \"to\": \"now\"\n        },\n        \"timepicker\": {\n          \"time_options\": [],\n          \"refresh_intervals\": []\n        },\n        \"templating\": {\n          \"list\": []\n        },\n        \"annotations\": {\n          \"list\": []\n        },\n        \"refresh\": \"5s\",\n        \"schemaVersion\": 17,\n        \"version\": 0,\n        \"links\": []\n      }\n    name: simple-dashboard.json\n"
    },
    "prometheus-operator": {
      "template": "\n- kind: OperatorGroup\n  apiVersion: operators.coreos.com/v1\n  metadata:\n    name: prometheus-operator-~PROJECT~\n    namespace: ~PROJECT~\n  spec:\n    targetNamespaces:\n    - ~PROJECT~\n- kind: Subscription\n  apiVersion: operators.coreos.com/v1alpha1\n  metadata:\n    name: prometheus-~PROJECT~\n    namespace: ~PROJECT~\n  spec:\n    channel: beta\n    installPlanApproval: Automatic\n    name: prometheus\n    source: community-operators\n    sourceNamespace: openshift-marketplace\n- kind: Prometheus\n  apiVersion: monitoring.coreos.com/v1\n  metadata:\n    name: ~NAME~-prometheus\n    labels:\n      prometheus: k8s\n    namespace: ~PROJECT~\n  spec:\n    replicas: ~REPLICAS~\n    serviceAccountName: prometheus-k8s\n    securityContext: {}\n    serviceMonitorSelector:\n      matchExpressions:\n      - key: k8s-app\n        operator: Exists\n    ruleSelector:\n      matchLabels:\n        role: prometheus-rulefiles\n        prometheus: k8s\n    alerting:\n      alertmanagers:\n      - namespace: ~PROJECT~\n        name: ~NAME~-alertmanager\n        port: web\n- kind: ServiceMonitor\n  apiVersion: monitoring.coreos.com/v1\n  metadata:\n    name: ~NAME~-servicemonitor\n    labels:\n      k8s-app: prometheus\n    namespace: ~PROJECT~\n  spec:\n    namespaceSelector:\n      matchNames:\n      - ~PROJECT~\n    selector:\n      matchLabels:\n        team: telegraf\n    endpoints:\n    - interval: 15s\n      path: /metrics\n      port: prometheus-client\n- kind: Alertmanager\n  apiVersion: monitoring.coreos.com/v1\n  metadata:\n    name: ~NAME~-alertmanager\n    namespace: ~PROJECT~\n  spec:\n    replicas: ~REPLICAS~\n    securityContext: {}\n- kind: PrometheusRule\n  apiVersion: monitoring.coreos.com/v1\n  metadata:\n    labels:\n      role: prometheus-rulefiles\n      prometheus: k8s\n    name: ~NAME~-prometheusrule\n    namespace: ~PROJECT~\n  spec:\n    groups:\n    - name: general.rules\n      rules:\n      - alert: TargetDown-serviceprom\n        annotations:\n          description: '{{ $value }}% of {{ $labels.job }} targets are down.'\n          summary: Targets are down\n          expr: 100 * (count(up == 0) BY (job) / count(up) BY (job)) > 10\n          for: 10m\n          labels:\n            severity: warning\n        expr: vector(1)\n      - alert: DeadMansSwitch-serviceprom\n        annotations:\n          description: This is a DeadMansSwitch meant to ensure that the entire Alerting pipeline is functional.\n          summary: Alerting DeadMansSwitch\n        expr: vector(1)\n        labels:\n          severity: none\n"
    }
  },
  "admin": {
    "fluentd": true,
    "grafana": true,
    "kube-state-metrics": true,
    "grafana-operator": true,
    "prometheus-operator": true
  }
}